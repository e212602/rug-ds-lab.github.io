@article{2020,
title = "Infrastructure Aware Heterogeneous-Workloads Scheduling for Data Center Energy Cost Minimization",
author = "Kawsar Haghshenas and Somayye Taheri and Maziar Goudarzi and Siamak Mohammadi",
pages = "1–1",
publisher = "Institute of Electrical and Electronics Engineers (IEEE)",
year = "2020",
url = "https://doi.org/10.1109",
doi = "10.1109/tcc.2020.2977040"
}


@article{2018,
title = "Fast and Energy Efficient CNFET Adders with CDM and Sensitivity Based Device-Circuit Co-Optimization",
author = "Kawsar Haghshenas and Mona Hashemi and Tooraj Nikoubin",
pages = "1–1",
publisher = "Institute of Electrical and Electronics Engineers (IEEE)",
year = "2018",
url = "https://doi.org/10.1109",
doi = "10.1109/tnano.2018.2834511"
}


@inproceedings{2015,
title = "CNTFET full-adders for energy-efficient arithmetic applications",
author = "Mahdieh Grailoo and Mona Hashemi and Kawsar Haghshenas and Shima Rezaee and Swetha Rapolu and Tooraj Nikoubin",
publisher = "IEEE",
month = "jul",
year = "2015",
url = "https://doi.org/10.1109",
doi = "10.1109/icccnt.2015.7395198"
}


@article{2019,
title = "MAGNETIC: Multi-Agent Machine Learning-Based Approach for Energy Efficient Dynamic Consolidation in Data Centers",
author = "Kawsar Haghshenas and Ali Pahlevan and Marina Zapater and Siamak Mohammadi and David Atienza",
pages = "1–1",
publisher = "Institute of Electrical and Electronics Engineers (IEEE)",
year = "2019",
url = "https://doi.org/10.1109",
doi = "10.1109/tsc.2019.2919555"
}


@article{haghshenas2020prediction,
year = "2020",
pages = "10240–10257",
number = "12",
volume = "76",
journal = "J. Supercomput.",
author = "Haghshenas, Kawsar and Mohammadi, Siamak",
title = "Prediction-based underutilized and destination host selection approaches for energy-efficient dynamic VM consolidation in data centers."
}


@inproceedings{Haghshenas_2022,
booktitle = "2022 IEEE International Conference on Big Data (Big Data)",
title = "CO<sub>2</sub> Emission Aware Scheduling for Deep Neural Network Training Workloads",
author = "Kawsar Haghshenas and Brian Setz and Marco Aiello",
publisher = "IEEE",
month = "dec",
year = "2022",
url = "https://doi.org/10.1109",
doi = "10.1109/bigdata55660.2022.10020544"
}


@conference{a72aacfbf7db4e878339b8ef8e0f086a,
note = "2022 IEEE International Conference on Big Data, Big Data 2022 ; Conference date: 17-12-2022 Through 20-12-2022",
pages = "1542–1549",
language = "English",
year = "2022",
author = "Kawsar Haghshenas and Brian Setz and Marco Aiello",
abstract = "Machine Learning (ML) training is a growing workload in high-performance computing clusters and data centers; furthermore, it is computationally intensive and requires substantial amounts of energy with associated emissions. To the best of our knowledge, previous works in the area of load management have never focused on decreasing the carbon emission of ML training workloads. In this paper, we explore the potential emission reduction achievable by leveraging the iterative nature of the training process as well as the variability of CO2 signal intensity as coming from the power grid. To this end, we introduce two emission-aware mechanisms to shift the training jobs in time and migrate them between geographical locations. We present experimental results on power and carbon emission of the training process together with delay overheads associated with emission reduction mechanisms, for various, representative, deep neural network models. The results show that following emission signals, one can effectively reduce emissions by an amount that varies from 13% to 57% of the baseline cases. Moreover, the experimental results show that the total delay overhead for applying emission-aware mechanisms multiple times is negligible compared to the jobs’ completion time.",
title = "CO2 Emission Aware Scheduling for Deep Neural Network Training Workloads"
}


@article{897c8975ca2f4e83bf3bf1f56cd4266e,
publisher = "Springer",
issn = "0920-8542",
journal = "Journal of supercomputing",
pages = "549–569",
volume = "80",
language = "English",
doi = "10.1007/s11227-023-05506-7",
year = "2023",
note = "Publisher Copyright: © 2023, The Author(s).",
author = "Tobias Piontek and Kawsar Haghshenas and Marco Aiello",
keywords = "Carbon-aware load shifting, CO signal following, CO signal prediction, Kubernetes, Workload scheduling",
abstract = "Decreasing carbon emissions of data centers while guaranteeing Quality of Service (QoS) is one of the major challenges for efficient resource management of large-scale cloud infrastructures and societal sustainability. Previous works in the area of carbon reduction mostly focus on decreasing overall energy consumption, replacing energy sources with renewable ones, and migrating workloads to locations where lower emissions are expected. These measures do not consider the energy mix of the power used for the data center. In other words, all KWh of energy are considered the same from the point of view of emissions, which is rarely the case in practice. In this paper, we overcome this deficit by proposing a novel practical CO2-aware workload scheduling algorithm implemented in the Kubernetes orchestrator to shift non-critical jobs in time. The proposed algorithm predicts future CO2 emissions by using historical data of energy generation, selects time-shiftable jobs, and creates job schedules utilizing greedy sub-optimal CO2 decisions. The proposed algorithm is implemented using Kubernetes’ scheduler extender solution due to its ease of deployment with little overheads. The algorithm is evaluated with real-world workload traces and compared to the default Kubernetes scheduling implementation on several actual scenarios.",
title = "Carbon emission-aware job scheduling for Kubernetes deployments"
}


@article{a9e46c5030564f6185196e5edd6475ea,
number = "1",
publisher = "SpringerOpen",
issn = "2520-8942",
journal = "Energy Informatics",
volume = "6",
language = "English",
doi = "10.1186/s42162-023-00269-0",
month = "December",
year = "2023",
note = "Publisher Copyright: © 2023, Springer Nature Switzerland AG.",
author = "Kawsar Haghshenas and Brian Setz and Yannis Blosch and Marco Aiello",
keywords = "Air cooling, Data center, Immersion cooling, Maintenance, Power density, Power usage efficiency",
abstract = "Air cooling is the traditional solution to chill servers in data centers. However, the continuous increase in global data center energy consumption combined with the increase of the racks’ power dissipation calls for the use of more efficient alternatives. Immersion cooling is one such alternative. In this paper, we quantitatively examine and compare air cooling and immersion cooling solutions. The examined characteristics include power usage efficiency (PUE), computing and power density, cost, and maintenance overheads. A direct comparison shows a reduction of about 50% in energy consumption and a reduction of about two-thirds of the occupied space, by using immersion cooling. In addition, the higher heat capacity of used liquids in immersion cooling compared to air allows for much higher rack power densities. Moreover, immersion cooling requires less capital and operational expenditures. However, challenging maintenance procedures together with the increased number of IT failures are the main downsides. By selecting immersion cooling, cloud providers must trade-off the decrease in energy and cost and the increase in power density with its higher maintenance and reliability concerns. Finally, we argue that retrofitting an air-cooled data center with immersion cooling will result in high costs and is generally not recommended.",
title = "Enough hot air: the role of immersion cooling"
}
